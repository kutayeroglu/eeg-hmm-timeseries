{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Poj-7iCoNaft",
        "outputId": "e8e3e72b-1086-4684-b3d8-7f79256290fb"
      },
      "id": "Poj-7iCoNaft",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
            "Downloading hmmlearn-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/164.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/164.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "144a7728-8a58-4aa2-b7f8-90ce28f9f275",
      "metadata": {
        "tags": [],
        "id": "144a7728-8a58-4aa2-b7f8-90ce28f9f275"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from hmmlearn import hmm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21866b21-82cd-4a3b-807e-159b2dd11e14",
      "metadata": {
        "tags": [],
        "id": "21866b21-82cd-4a3b-807e-159b2dd11e14"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "patients = 5\n",
        "channels_per_series = 750\n",
        "time_points = 10240  # 20 seconds at 512 Hz\n",
        "sampling_rate = 512  # Hz\n",
        "\n",
        "# Time array\n",
        "time = np.linspace(0, 20, time_points)  # 20 seconds\n",
        "\n",
        "# Function to generate synthetic signals\n",
        "def generate_focal_signal(time, noise_level=0.5):\n",
        "    \"\"\"Generate synthetic focal signal (seizure-like).\"\"\"\n",
        "    base_signal = 3 * np.sin(2 * np.pi * 10 * time)  # High frequency component (10 Hz)\n",
        "    noise = noise_level * np.random.normal(size=len(time))  # Random noise\n",
        "    return base_signal + noise\n",
        "\n",
        "def generate_nonfocal_signal(time, noise_level=0.2):\n",
        "    \"\"\"Generate synthetic nonfocal signal (healthy-like).\"\"\"\n",
        "    base_signal = np.sin(2 * np.pi * 2 * time)  # Low frequency component (2 Hz)\n",
        "    noise = noise_level * np.random.normal(size=len(time))  # Random noise\n",
        "    return base_signal + noise\n",
        "\n",
        "# Generate synthetic data\n",
        "synthetic_data = {}\n",
        "\n",
        "for patient in range(1, patients + 1):\n",
        "    patient_data = {\"F_series\": [], \"N_series\": []}\n",
        "\n",
        "    for channel in range(channels_per_series):\n",
        "        # Focal series (F-series)\n",
        "        focal_x = generate_focal_signal(time)\n",
        "        focal_y = focal_x * 0.8 + np.random.normal(0, 0.3, size=len(time))\n",
        "        patient_data[\"F_series\"].append((focal_x, focal_y))\n",
        "\n",
        "        # Nonfocal series (N-series)\n",
        "        nonfocal_x = generate_nonfocal_signal(time)\n",
        "        nonfocal_y = nonfocal_x * 0.9 + np.random.normal(0, 0.1, size=len(time))\n",
        "        patient_data[\"N_series\"].append((nonfocal_x, nonfocal_y))\n",
        "\n",
        "    synthetic_data[f\"Patient_{patient}\"] = patient_data\n",
        "\n",
        "# Data is stored in the `synthetic_data` dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d22da5b-4b15-471f-9130-1f83257725c8",
      "metadata": {
        "tags": [],
        "id": "0d22da5b-4b15-471f-9130-1f83257725c8"
      },
      "outputs": [],
      "source": [
        "# Get data for Patient 1\n",
        "patient_1_data = synthetic_data[\"Patient_1\"]\n",
        "\n",
        "# Get focal signal for the first channel of Patient 1\n",
        "focal_x, focal_y = patient_1_data[\"F_series\"][0]\n",
        "\n",
        "# Get nonfocal signal for the first channel of Patient 1\n",
        "nonfocal_x, nonfocal_y = patient_1_data[\"N_series\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1efd1c4d-ba59-45e1-809b-f3fde684c8c2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1efd1c4d-ba59-45e1-809b-f3fde684c8c2",
        "outputId": "335a8e17-f50f-4157-bfd3-4548d6ced03e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-493f3f211157>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Fit the model to the combined data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_data_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Now, the model is trained and can be used for decoding sequences or inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_estep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Compute lower bound before updating model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36m_do_estep\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0mcurr_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msub_X\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_X_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposteriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwdlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwdlattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m             \u001b[0;31m# Derived HMM classes will implement the following method to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;31m# update their probability distributions, so keep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36m_fit_log\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    886\u001b[0m         bwdlattice = _hmmc.backward_log(\n\u001b[1;32m    887\u001b[0m             self.startprob_, self.transmat_, log_frameprob)\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0mposteriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_posteriors_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfwdlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwdlattice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_frameprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposteriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwdlattice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwdlattice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hmmlearn/base.py\u001b[0m in \u001b[0;36m_compute_posteriors_log\u001b[0;34m(self, fwdlattice, bwdlattice)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# pruned too aggressively.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mlog_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfwdlattice\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbwdlattice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mlog_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_gamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize an array to hold all observed data from all patients\n",
        "all_observed_data = []\n",
        "\n",
        "# Loop through the synthetic data for 5 patients\n",
        "for patient_idx in range(1, patients + 1):  # Iterating through 5 patients\n",
        "    # Get the F-series (focal signals) for each patient\n",
        "    patient_data = synthetic_data[f\"Patient_{patient_idx}\"]\n",
        "\n",
        "    # For simplicity, we'll use the 'focal_x' signal from each channel\n",
        "    # Extract 'focal_x' from each channel in the patient's F-series\n",
        "    # 'patient_data[\"F_series\"]' is a list of tuples: (focal_x, focal_y)\n",
        "    for channel_data in patient_data[\"F_series\"]:\n",
        "        focal_x = channel_data[0]  # Extract focal_x (first element of the tuple)\n",
        "        all_observed_data.append(focal_x)  # Add focal_x to the observed data list\n",
        "\n",
        "# Combine the data from all patients into a single array for fitting\n",
        "combined_data = np.concatenate(all_observed_data)  # Concatenate all patient data into one array\n",
        "\n",
        "# Reshape the data to fit the HMM (HMM expects 2D data: samples x features)\n",
        "combined_data_reshaped = combined_data.reshape(-1, 1)\n",
        "\n",
        "# Fit the HMM model\n",
        "model = hmm.GaussianHMM(n_components=3, covariance_type=\"diag\", n_iter=1000)\n",
        "\n",
        "# Fit the model to the combined data\n",
        "model.fit(combined_data_reshaped)\n",
        "\n",
        "# Now, the model is trained and can be used for decoding sequences or inference\n",
        "print(\"HMM training completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716e29e4-8994-497f-aa11-8173d684ab91",
      "metadata": {
        "id": "716e29e4-8994-497f-aa11-8173d684ab91"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}